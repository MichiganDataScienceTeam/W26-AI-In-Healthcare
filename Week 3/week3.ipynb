{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPw+gLS/njbeHhNq6rpkfLQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Feature Engineering and Machine Learning\n","\n","### **All exercises will be using your chosen dataset**\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"QPxsavPk_OY2"}},{"cell_type":"markdown","source":["## Step 1: Import your dataset using the tutorial from the slides"],"metadata":{"id":"fMSaoJiUeiD-"}},{"cell_type":"markdown","source":["## Step 2: Install necessary libraries. We are using Scikit Learn for week 3"],"metadata":{"id":"8r-ivtAWe2EF"}},{"cell_type":"code","source":["!pip install pandas numpy scikit-learn matplotlib\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import joblib\n","from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, r2_score, accuracy_score, classification_report, ConfusionMatrixDisplay"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q9E7DBflf3gN","executionInfo":{"status":"ok","timestamp":1769743886568,"user_tz":300,"elapsed":3582,"user":{"displayName":"Seena Simkani","userId":"16110548119654491643"}},"outputId":"dff5774e-c082-45a9-9345-3e84d0d9c7f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}]},{"cell_type":"markdown","source":["## Exercises\n","\n","### Scikit-Learn Docs, ML Interpretability Book, and Demo for Reference\n","\n","#### [Scikit-Learn](https://scikit-learn.org/stable/)\n","#### [ML Interpretability](https://christophm.github.io/interpretable-ml-book/)\n","#### [Demo](https://mdst-ai-in-healthcare.streamlit.app/)"],"metadata":{"id":"p_cbkhtWfgkC"}},{"cell_type":"markdown","source":["Import your **preprocessed dataset**"],"metadata":{"id":"56PHK_sDYbE2"}},{"cell_type":"code","source":["# TODO: Load your dataset with pandas"],"metadata":{"id":"M5Y9NB4thXzs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exercise 1: Feature Creation"],"metadata":{"id":"RFEDeUJnXrO-"}},{"cell_type":"markdown","source":["Creating new features from the one that you already have can enhance model performance and interpretability."],"metadata":{"id":"oQNOQML7W3Xi"}},{"cell_type":"code","source":["# TODO: Choose a numerical feature (df['num_feature']) and use pd.cut() to bin the feature into categorical bins.\n","num_feature = ..."],"metadata":{"id":"FJ4-4BDZXwlX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The Log transformation most effective on data that is right-skewed by shrinking the right tail and creating a more normal distribution. It is also used for transforming data to be more robust to outliers"],"metadata":{"id":"vXkvFKijYqUy"}},{"cell_type":"code","source":["# TODO: Choose a numerical feature to use log transformation on. Use numpy.log1p()\n","num_feature = ..."],"metadata":{"id":"Jr9zr88PXyUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Create an interaction feature from existing ones that you think would help enhance the model. This might require some research\n","# (e.g., house_size * location_quality or weight / height^2).\n"],"metadata":{"id":"tLkdtBaMYjW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exercise 2: Encoding"],"metadata":{"id":"0lnto8CffkFl"}},{"cell_type":"markdown","source":["Dummy encoding is a technique for converting categorical variables into columns of 1's and 0's So the model can utilize these features for making predictions. This comes at the cost of increased dimensionality. Dummy encoding is typically done on a categorical variable that doesn't have a particular order (e.g., low, medium, high)"],"metadata":{"id":"FjpcJ2RWUFuV"}},{"cell_type":"code","source":["# TODO: Choose a categorical feature to encode using dummy encoding (use the drop_first = True argument)"],"metadata":{"id":"x917B9idVd3d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ordinal Encoding is used for encoding categorical variables that have a particular order to them (e.g., low, medium, high)"],"metadata":{"id":"OhabjjAxWFCI"}},{"cell_type":"code","source":["# TODO: Choose a categorical feature to encode using ordinal encoding and define the encoder\n","# use OrdinalEncoder(categories = [['low','medium', 'high']])\n","encoder = ..."],"metadata":{"id":"md2Au90SWEVs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Use ordinal encoding to encode variable and put it into a new column in the dataframe\n","# use encoder.fit_transform(df[['feature']])"],"metadata":{"id":"7agbNgZOWSHW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exercise 3: Scaling"],"metadata":{"id":"0FW53gQHtdKT"}},{"cell_type":"markdown","source":["Before creating a model, it's good practice to use StandardScaler(). This is a preprocessing tool from scikit-learn which is used for transforming a numerical data distribution to have a mean of 0 and a standard deviation of 1. This ensures that no feature dominates the model soley because it has larger numerical values."],"metadata":{"id":"7qqM6SlWbVQO"}},{"cell_type":"code","source":["# TODO: Choose the numerical columns that you want to have standardized.\n","cols = [...]"],"metadata":{"id":"jZNLhQtHbKzV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Split the data into the features that you want to use (X) and the target (y).\n","# Choose any columns/festures that you think might create a good model\n","X = ...\n","y = ..."],"metadata":{"id":"9BqkjA7w3wkw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We are now going to split the data into train and test sets. It is standard to use a test set size that is 20% of your total data and the remaining data for model training"],"metadata":{"id":"SecuVPwy3R6m"}},{"cell_type":"code","source":["# TODO: Split the data into train data and test data. use train_test_split(X, y, test_size=0.2, random_state=42)\n","# it is important to scale the training and testing data separately to prevent data leakage\n","\n","# X_train, X_test, y_train, y_test = ..."],"metadata":{"id":"h3eDK-0H31LB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Initialize the scaler (scaler = StandardScaler())\n","scaler = ..."],"metadata":{"id":"BP2VO0dmcEfX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: use scaler.fit_transform(X_train[cols]) for the standard scaler to transform training data\n","\n","# X_train[cols] = ..."],"metadata":{"id":"XIUR2RhqcWu1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: use scale.transform(y_train[cols]) to transform the test data\n","\n","# X_test[cols] = ..."],"metadata":{"id":"uAgLYown4yUd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run this line of code to save the scaler as you will need it later\n","joblib.dump(scaler, 'scaler.pkl')"],"metadata":{"id":"IajRG-Hc547r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exercise 4: Model Creation"],"metadata":{"id":"KWTU2UnGhNoe"}},{"cell_type":"markdown","source":["Now it's time to create some models! For the purposes of this exercise, we will only be exploring linear regression and logistic regression."],"metadata":{"id":"zP8wZXjZdDQ7"}},{"cell_type":"markdown","source":["**Do these exercises if your target is numerical**. The machine learning task in this case would be **regression**."],"metadata":{"id":"DwgiyofbdsPy"}},{"cell_type":"markdown","source":["Here, we will create a linear regression model."],"metadata":{"id":"Z06ckuVyhjZw"}},{"cell_type":"code","source":["# TODO: Define a linear regression model. (LinearRegression())\n","linear_model = ..."],"metadata":{"id":"UGD5Knx7dr2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Fit the model using the training data\n","\n","# linear_model.fit(...)"],"metadata":{"id":"jBUsCCQ2gJ5n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: use .predict() on the testing data to make predictions\n","linear_model_predictions = ..."],"metadata":{"id":"mrnzWaW8g_gi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: calculate the model coefficients using coef_"],"metadata":{"id":"h0XYSnRSSbVJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The model coefficients are also called the **model parameters** which determine how much each feature has an effect on the model. Come up with an interpretation of what the model parameter for one of your features mean for the linear model (the order of the coefficients is the same as the order of the dataset that was used to train the model. Also remember that if you standardized a feature, the interpretation should be in standard deviation units):"],"metadata":{"id":"59GMy8_KSZwl"}},{"cell_type":"markdown","source":["**Do these exercises if your target is categorical**. The machine learning task in this case would be **classification**."],"metadata":{"id":"bkIbf7H0d4no"}},{"cell_type":"markdown","source":["Logistic Regression is a model that maps the input data to an S-shaped curve and uses a threshold (0.5) to predict the probability of a certain categorical class. It then outputs the most probable class."],"metadata":{"id":"HiqUHglwjYuo"}},{"cell_type":"code","source":["# TODO: Define a logistic regression model. (LogisticRegression())\n","logistic_model = ..."],"metadata":{"id":"C_82yMK1d9wI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Fit the model using the traning data\n","\n","# logistic_model.fit(...)"],"metadata":{"id":"_lAPIzG3jR4h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: use .predict() on the testing data to make predictions\n","logistic_model_predictions = ..."],"metadata":{"id":"KGU4s9cUjVpI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: use coef_ to display the model coefficients used for the logistic regression model"],"metadata":{"id":"kwf3yobXTY1Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The model coefficients are also called the **model parameters** which determine how much each feature has an effect on the model. Come up with an interpretation of what the model parameter for one of your features mean for the logistic regression model (the order of the coefficients is the same as the order of the dataset that was used to train the model):"],"metadata":{"id":"dRW2cUa1TX84"}},{"cell_type":"markdown","source":["These models are what we call **inherently interpretable**. Models that are not inherently interpretable include Random Forest, Neural Networks, etc..."],"metadata":{"id":"e7q8MJh4TjbA"}},{"cell_type":"markdown","source":["### Exercise 5: Model Evaluations"],"metadata":{"id":"myqpmp_khNsY"}},{"cell_type":"markdown","source":["In this section, we will be evaluating the performance of the model that you trained above."],"metadata":{"id":"dYbUur6dkm3_"}},{"cell_type":"markdown","source":["Do these exercises if you trained a **linear regression** model."],"metadata":{"id":"5m9ND-U2UrbY"}},{"cell_type":"code","source":["# TODO: calculate mean squared error using mean_squared_error on the test data"],"metadata":{"id":"jPnd6rBXVg_n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The mean squared error is the **cost function** of the linear regression model. The best fit line minimizes the average squared loss between the true and predicted values in the data. Since the error is squared, how sensitive is this value to outliers in the data?"],"metadata":{"id":"SPKp7xqZWUiF"}},{"cell_type":"code","source":["# TODO: calculate root mean squared error using root_mean_sqaured_error on the test data"],"metadata":{"id":"7unDR7uiV5ly"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Root Mean Squared Error is a more interpretable since the units are converted back into the units of the target variable. interpret the value of RMSE in the context of your data:"],"metadata":{"id":"SjoSQ0chXzKw"}},{"cell_type":"code","source":["# TODO: calculate mean absolute error using mean_absolute_error on the test data"],"metadata":{"id":"vstVGznfV_CU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This value tells us the average distance between the true data points in our test set and the predicted values. How robust is mean absolute error to outliers?"],"metadata":{"id":"TX9CT9ViW3Z7"}},{"cell_type":"code","source":["# TODO: calculate r^2 score using r2_score"],"metadata":{"id":"lg7HHLbWWCds"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The r^2 value is used to determine how much of the target variance was explained by our value. a value of 0 explains none of the variance while a value of 1 means that the model is a perfect fit to the data."],"metadata":{"id":"aN4JGvWLYJif"}},{"cell_type":"markdown","source":["Do these exercises if you trained a **logistic regression** model."],"metadata":{"id":"XyCK6ZuFUxy8"}},{"cell_type":"code","source":["# TODO: calculate the accuracy of the model using accuracy_score"],"metadata":{"id":"kTCRaC7_UxVF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This determines the percentage of instances in the test data that were classified correctly."],"metadata":{"id":"KASFG_YOZEd5"}},{"cell_type":"code","source":["# TODO: print a classification report using classification_report"],"metadata":{"id":"B1ytr4dMWMCX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Precision: Measures the accuracy of positive predictions in the class (higher value means less false positives)\n","\n","Recall: The ability to find all actual positives in the class (higher value means less false negatives)\n","\n","F1 Score: balancing metric of the precision and recall\n","\n","Support: Number of actual occurences in that class"],"metadata":{"id":"vLsFplSMaKkz"}},{"cell_type":"markdown","source":["Determine the accuracy of the model when it comes to false positives and negatives:"],"metadata":{"id":"fAF99yfYdG5B"}},{"cell_type":"markdown","source":["### Exercise 6: Model Visualizations"],"metadata":{"id":"prRR9MzDhNua"}},{"cell_type":"markdown","source":["Do these exercises if you trained a **linear regression** model."],"metadata":{"id":"Rw4Rc0GdVFT7"}},{"cell_type":"code","source":["# TODO: create a variable for the residuals (actual - predicted) for the linear model\n","residuals = ..."],"metadata":{"id":"XCBuDS7kdy3D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: create a scatter plot of the residuals vs. predictions using plt.scatter()\n","\n","# plt.scatter(...)\n","\n","# this line of code creates a line through y = 0\n","plt.axhline(y=0, color='r', linestyle='-')\n","plt.show()"],"metadata":{"id":"DSs6i1uNeSaF","executionInfo":{"status":"ok","timestamp":1769743886834,"user_tz":300,"elapsed":177,"user":{"displayName":"Seena Simkani","userId":"16110548119654491643"}},"colab":{"base_uri":"https://localhost:8080/","height":435},"outputId":"2f978901-7d30-4f72-8500-95630d96727c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["Determine how the residuals are distributed. If they are randomly scattered around the y=0 line, this indicates a good linear fit."],"metadata":{"id":"Er78EyLne65p"}},{"cell_type":"markdown","source":["Do these exercises if you trained a **logistic regression** model."],"metadata":{"id":"PRkjOD6nVG1V"}},{"cell_type":"code","source":["# TODO: Create a confusion matrix using the test and prediction data. use the normalize=\"true\" argument\n","\n","\n","# ConfusionMatrixDisplay.from_predictions(...)\n","# plt.title(\"Confusion Matrix\")\n","# plt.show()"],"metadata":{"id":"jkL1y7rUdzy5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This is a more visual understanding of how the model made predictions for the different classes in the target variable. Summarize how the model makes its predictions. Specifically, why might the model be giving false positives or false negatives for certain classes? What factors could be influencing the models predictions such as the distribution of the target variable, potential overfitting, etc..."],"metadata":{"id":"pXBgCVE4frvt"}},{"cell_type":"markdown","source":["### Exercise 7: Further Exploration"],"metadata":{"id":"XmSfWzKtruhq"}},{"cell_type":"markdown","source":["Keep experimenting with different ways to transform your data to make it model ready. Also, try out different models and see how performance is impacted."],"metadata":{"id":"68PjCI4YrxC5"}},{"cell_type":"markdown","source":["You can save your model, train data, test data etc.. as well using joblib.dump() as we did with the scaler"],"metadata":{"id":"n7El4TNAKKr3"}}]}